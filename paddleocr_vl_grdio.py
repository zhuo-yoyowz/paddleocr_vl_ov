import gradio as gr
import torch
from PIL import Image
import time
import openvino as ov
from transformers.utils.chat_template_utils import render_jinja_template
from ov_paddleocr_vl import OVPaddleOCRVLForCausalLM
from image_processing_paddleocr_vl import PaddleOCRVLImageProcessor
import requests
from pathlib import Path
from urllib.parse import urlparse
import os
import re

# åœ¨å¯¼å…¥åç«‹å³è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé¿å…Gradioåˆå§‹åŒ–æ—¶çš„ç½‘ç»œè¯·æ±‚
os.environ.setdefault("GRADIO_ANALYTICS_ENABLED", "False")
os.environ.setdefault("GRADIO_SERVER_NAME", "127.0.0.1")
os.environ.setdefault("NO_PROXY", "127.0.0.1,localhost")
os.environ.setdefault("no_proxy", "127.0.0.1,localhost")

# å…¨å±€å˜é‡
paddleocr_vl_model = None
my_preprocessor = None

# ä»»åŠ¡æç¤ºè¯
PROMPTS = {
    "ocr": "OCR:",
    "table": "Table Recognition:",
    "formula": "Formula Recognition:",
    "chart": "Chart Recognition:",
}

# Chatæ¨¡æ¿ï¼ˆä»chat_template.jinjaæ–‡ä»¶è¯»å–ï¼‰
CHAT_TEMPLATE = '''{%- if not add_generation_prompt is defined -%}
    {%- set add_generation_prompt = true -%}
{%- endif -%}
{%- if not cls_token is defined -%}
    {%- set cls_token = "<|begin_of_sentence|>" -%}
{%- endif -%}
{%- if not eos_token is defined -%}
    {%- set eos_token = "</s>" -%}
{%- endif -%}
{%- if not image_token is defined -%}
    {%- set image_token = "<|IMAGE_START|><|IMAGE_PLACEHOLDER|><|IMAGE_END|>" -%}
{%- endif -%}
{{- cls_token -}}
{%- for message in messages -%}
    {%- if message["role"] == "user" -%}
        {{- "User: " -}}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "image" -%}
                {{ image_token }}
            {%- endif -%}
        {%- endfor -%}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] }}
            {%- endif -%}
        {%- endfor -%}
        {{ "\\n" -}}
    {%- elif message["role"] == "assistant" -%}
        {{- "Assistant: " -}}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] }}
            {%- endif -%}
        {%- endfor -%}
        {{ eos_token -}}
    {%- elif message["role"] == "system" -%}
        {%- for content in message["content"] -%}
            {%- if content["type"] == "text" -%}
                {{ content["text"] + "\\n" }}
            {%- endif -%}
        {%- endfor -%}
    {%- endif -%}
{%- endfor -%}
{%- if add_generation_prompt -%}
    {{- "Assistant: " -}}
{%- endif -%}'''

def load_chat_template(template_path=None):
    """åŠ è½½chatæ¨¡æ¿"""
    global CHAT_TEMPLATE
    if template_path:
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                CHAT_TEMPLATE = f.read()
            return f"âœ… å·²ä»æ–‡ä»¶åŠ è½½æ¨¡æ¿: {template_path}"
        except Exception as e:
            return f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿"
    return "ä½¿ç”¨é»˜è®¤æ¨¡æ¿"

def initialize_model(ov_model_path="./ov_paddleocr_vl_model", 
                     device_type="GPU", 
                     llm_int4_compress=False, 
                     vision_int8_quant=False, 
                     llm_int8_quant=False,
                     template_path=None):
    """åˆå§‹åŒ–æ¨¡å‹"""
    global paddleocr_vl_model, my_preprocessor
    
    try:
        # åŠ è½½chatæ¨¡æ¿
        if template_path:
            load_chat_template(template_path)
        
        # åˆå§‹åŒ–OpenVINOæ¨¡å‹
        core = ov.Core()
        llm_infer_list = []
        vision_infer = []
        
        paddleocr_vl_model = OVPaddleOCRVLForCausalLM(
            core=core,
            ov_model_path=ov_model_path,
            device=device_type,
            llm_int4_compress=llm_int4_compress,
            vision_int8_quant=vision_int8_quant,
            llm_int8_quant=llm_int8_quant,
            llm_infer_list=llm_infer_list,
            vision_infer=vision_infer
        )
        
        # åˆå§‹åŒ–å›¾åƒé¢„å¤„ç†å™¨
        my_preprocessor = PaddleOCRVLImageProcessor(
            resample=3,  # PIL.Image.Resampling.LANCZOS
            rescale_factor=0.00392156862745098,  # 1/255
            image_mean=[0.5, 0.5, 0.5],
            image_std=[0.5, 0.5, 0.5],
            min_pixels=147384,
            max_pixels=2822400,
            patch_size=14,
            temporal_patch_size=1,
            merge_size=2
        )
        
        return "âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼"
    except Exception as e:
        return f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {str(e)}"

def format_ocr_result(text):
    """
    æ ¼å¼åŒ–OCRè¯†åˆ«ç»“æœï¼Œå¤„ç†ç‰¹æ®Šæ ‡è®°
    æ”¯æŒæ ¼å¼ï¼š
    - <fcel> è¡¨æ ¼å•å…ƒæ ¼æ ‡è®°ï¼ˆæ ¼å¼ï¼š<fcel>å†…å®¹<fcel>ï¼‰
    - <nl> æ¢è¡Œæ ‡è®°
    
    æ³¨æ„ï¼šæ ¼å¼æ˜¯ <fcel>å†…å®¹<fcel>ï¼Œå³å¼€å§‹å’Œç»“æŸéƒ½æ˜¯ <fcel>
    åªæœ‰æ£€æµ‹åˆ°è¡¨æ ¼æ ¼å¼æ—¶æ‰è½¬æ¢ä¸ºMarkdownè¡¨æ ¼ï¼Œå¦åˆ™åªæ¸…ç†æ ‡è®°
    """
    if not text:
        return text
    
    # å…ˆæ›¿æ¢æ¢è¡Œæ ‡è®°
    text = text.replace('<nl>', '\n')
    
    # æ£€æµ‹æ˜¯å¦æ˜¯è¡¨æ ¼æ ¼å¼ï¼ˆåŒ…å«å¤šä¸ª<fcel>æ ‡è®°ï¼‰
    # éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ª<fcel>æ ‡è®°ï¼Œä¸”è‡³å°‘æœ‰ä¸€è¡ŒåŒ…å«å¤šä¸ªå•å…ƒæ ¼
    is_table_format = False
    if '<fcel>' in text:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤šè¡ŒåŒ…å«<fcel>æ ‡è®°ï¼Œæˆ–è€…å•è¡ŒåŒ…å«å¤šä¸ª<fcel>æ ‡è®°
        lines_with_fcel = [line for line in text.split('\n') if '<fcel>' in line]
        if len(lines_with_fcel) > 0:
            # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æœ‰å¤šä¸ª<fcel>æ ‡è®°ï¼ˆè‡³å°‘2ä¸ªï¼Œè¡¨ç¤ºæœ‰å¤šä¸ªå•å…ƒæ ¼ï¼‰
            first_line_fcel_count = lines_with_fcel[0].count('<fcel>')
            if first_line_fcel_count >= 2:
                is_table_format = True
    
    if is_table_format:
        # æŒ‰è¡Œåˆ†å‰²
        lines = text.split('\n')
        table_rows = []
        
        for line in lines:
            if '<fcel>' in line:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ‰€æœ‰ <fcel>å†…å®¹<fcel> æ ¼å¼çš„å•å…ƒæ ¼
                # æ ¼å¼æ˜¯ <fcel>å†…å®¹<fcel>ï¼Œæ‰€ä»¥éœ€è¦åŒ¹é… <fcel> åˆ°ä¸‹ä¸€ä¸ª <fcel> ä¹‹é—´çš„å†…å®¹
                # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œä½†éœ€è¦ç¡®ä¿åŒ¹é…æ‰€æœ‰å•å…ƒæ ¼
                
                # æ–¹æ³•ï¼šæ‰¾åˆ°æ‰€æœ‰ <fcel> æ ‡è®°çš„ä½ç½®ï¼Œç„¶åæå–æ¯å¯¹ä¹‹é—´çš„å†…å®¹
                fcel_positions = [m.start() for m in re.finditer(r'<fcel>', line)]
                
                if len(fcel_positions) >= 2:
                    row_cells = []
                    # æ¯ä¸¤ä¸ªè¿ç»­çš„ <fcel> ä¹‹é—´æ˜¯ä¸€ä¸ªå•å…ƒæ ¼
                    for i in range(0, len(fcel_positions) - 1):
                        start_pos = fcel_positions[i] + len('<fcel>')
                        end_pos = fcel_positions[i + 1]
                        cell_content = line[start_pos:end_pos].strip()
                        row_cells.append(cell_content)
                    
                    # å¦‚æœæœ€åä¸€ä¸ª <fcel> åé¢è¿˜æœ‰å†…å®¹ï¼ˆæ²¡æœ‰ç»“æŸçš„ <fcel>ï¼‰ï¼Œä¹Ÿæå–
                    if len(fcel_positions) > 0:
                        last_fcel_pos = fcel_positions[-1] + len('<fcel>')
                        # æ£€æŸ¥æœ€åä¸€ä¸ª <fcel> åé¢æ˜¯å¦è¿˜æœ‰å†…å®¹ï¼ˆä¸æ˜¯æ¢è¡Œç¬¦æˆ–ç»“æŸï¼‰
                        remaining = line[last_fcel_pos:].strip()
                        # ç§»é™¤å¯èƒ½çš„ <nl> æ ‡è®°
                        remaining = remaining.replace('<nl>', '').strip()
                        if remaining:
                            row_cells.append(remaining)
                    
                    if row_cells:
                        table_rows.append(row_cells)
        
        if table_rows and len(table_rows) > 0:
            # æ‰¾åˆ°æœ€å¤§åˆ—æ•°ï¼ˆç”¨äºå¯¹é½ï¼‰
            max_cols = max(len(row) for row in table_rows)
            
            # è½¬æ¢ä¸ºMarkdownè¡¨æ ¼
            md_table = ""
            
            # åˆ›å»ºè¡¨å¤´ï¼ˆç¬¬ä¸€è¡Œï¼‰
            if len(table_rows) > 0:
                header = table_rows[0].copy()
                # è¡¥é½åˆ—æ•°
                while len(header) < max_cols:
                    header.append("")
                md_table += "| " + " | ".join(header) + " |\n"
                md_table += "| " + " | ".join(["---"] * max_cols) + " |\n"
                
                # æ·»åŠ æ•°æ®è¡Œ
                for row in table_rows[1:]:
                    row_copy = row.copy()
                    # ç¡®ä¿è¡Œé•¿åº¦ä¸æœ€å¤§åˆ—æ•°ä¸€è‡´
                    while len(row_copy) < max_cols:
                        row_copy.append("")
                    md_table += "| " + " | ".join(row_copy[:max_cols]) + " |\n"
            
            return md_table
    
    # å¦‚æœä¸æ˜¯è¡¨æ ¼æ ¼å¼ï¼Œåªæ¸…ç†æ ‡è®°ï¼Œä¿æŒåŸå§‹æ–‡æœ¬æ ¼å¼
    # ç§»é™¤<fcel>æ ‡è®°ï¼Œä½†ä¿ç•™å…¶ä»–å†…å®¹å’Œæ¢è¡Œ
    text = text.replace('<fcel>', '')
    text = text.replace('</fcel>', '')
    # <nl>å·²ç»åœ¨å¼€å¤´æ›¿æ¢ä¸º\näº†ï¼Œè¿™é‡Œä¸éœ€è¦å†å¤„ç†
    
    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™åˆç†çš„ç©ºè¡Œï¼‰
    lines = text.split('\n')
    cleaned_lines = []
    prev_empty = False
    for line in lines:
        line = line.strip()
        if line:
            cleaned_lines.append(line)
            prev_empty = False
        elif not prev_empty:
            cleaned_lines.append('')
            prev_empty = True
    
    return '\n'.join(cleaned_lines)

def load_image_from_source(image_source):
    """ä»ä¸åŒæ¥æºåŠ è½½å›¾ç‰‡ï¼šPIL Imageå¯¹è±¡ã€æœ¬åœ°è·¯å¾„æˆ–URL"""
    if image_source is None:
        return None
    
    # å¦‚æœå·²ç»æ˜¯PIL Imageå¯¹è±¡ï¼Œç›´æ¥è¿”å›
    if isinstance(image_source, Image.Image):
        return image_source
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ¤æ–­æ˜¯URLè¿˜æ˜¯æœ¬åœ°è·¯å¾„
    if isinstance(image_source, str):
        # æ£€æŸ¥æ˜¯å¦æ˜¯URL
        parsed = urlparse(image_source)
        if parsed.scheme in ('http', 'https'):
            # ä»URLä¸‹è½½å›¾ç‰‡
            try:
                response = requests.get(image_source, stream=True, timeout=10)
                response.raise_for_status()
                image = Image.open(response.raw)
                return image
            except Exception as e:
                raise Exception(f"æ— æ³•ä»URLåŠ è½½å›¾ç‰‡: {str(e)}")
        else:
            # æœ¬åœ°æ–‡ä»¶è·¯å¾„
            try:
                path = Path(image_source)
                if not path.exists():
                    raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {image_source}")
                image = Image.open(image_source)
                return image
            except Exception as e:
                raise Exception(f"æ— æ³•ä»æœ¬åœ°è·¯å¾„åŠ è½½å›¾ç‰‡: {str(e)}")
    
    return image_source

def process_ocr(image, image_url_or_path, task_type, max_new_tokens, custom_prompt):
    """å¤„ç†OCRè¯†åˆ«"""
    global paddleocr_vl_model, my_preprocessor
    
    if paddleocr_vl_model is None or my_preprocessor is None:
        return "âŒ è¯·å…ˆåˆå§‹åŒ–æ¨¡å‹ï¼", None, None
    
    # ç¡®å®šä½¿ç”¨å“ªä¸ªå›¾ç‰‡æº
    image_source = None
    if image is not None:
        image_source = image
    elif image_url_or_path and image_url_or_path.strip():
        image_source = image_url_or_path.strip()
    
    if image_source is None:
        return "âŒ è¯·ä¸Šä¼ å›¾ç‰‡ã€è¾“å…¥å›¾ç‰‡è·¯å¾„æˆ–URLï¼", None, None
    
    try:
        # åŠ è½½å›¾ç‰‡ï¼ˆæ”¯æŒPIL Imageã€æœ¬åœ°è·¯å¾„æˆ–URLï¼‰
        loaded_image = load_image_from_source(image_source)
        if loaded_image is None:
            return "âŒ æ— æ³•åŠ è½½å›¾ç‰‡ï¼", None, None
        
        # å‡†å¤‡æç¤ºè¯
        if custom_prompt and custom_prompt.strip():
            prompt_text = custom_prompt.strip()
        else:
            prompt_text = PROMPTS.get(task_type, "OCR:")
        
        # è½¬æ¢å›¾ç‰‡ä¸ºRGB
        image_rgb = loaded_image.convert("RGB")
        
        # å›ºå®šè°ƒæ•´å›¾ç‰‡å¤§å°ä¸º1200x800ï¼ˆä¸ç”¨æˆ·ä»£ç ä¿æŒä¸€è‡´ï¼‰
        target_width = 1200
        target_height = 800
        image_rgb = image_rgb.resize((target_width, target_height), Image.Resampling.LANCZOS)
        
        # å‡†å¤‡æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "image", "image": image_rgb},
                    {"type": "text", "text": prompt_text},
                ]
            }
        ]
        
        # ä½¿ç”¨render_jinja_templateå¤„ç†æ–‡æœ¬
        text, generation_indices = render_jinja_template(
            conversations=[messages],
            chat_template=CHAT_TEMPLATE,
            add_generation_prompt=True,
            return_tensors="pt",
        )
        
        # å¤„ç†å›¾åƒ
        images_info = my_preprocessor(images=image_rgb, return_tensors="pt")
        
        # å¤„ç†å›¾åƒå ä½ç¬¦
        if not isinstance(text, list):
            text = [text]
        
        index = 0
        for i in range(len(text)):
            while "<|IMAGE_PLACEHOLDER|>" in text[i]:
                placeholder_count = (
                    images_info['image_grid_thw'][index].prod()
                    // 2
                    // 2
                )
                text[i] = text[i].replace(
                    "<|IMAGE_PLACEHOLDER|>",
                    "<|placeholder|>" * placeholder_count,
                    1,
                )
                index += 1
            text[i] = text[i].replace("<|placeholder|>", "<|IMAGE_PLACEHOLDER|>")
        
        # Tokenizeæ–‡æœ¬
        text_inputs = paddleocr_vl_model.tokenizer(text, return_tensors="pt")
        
        # å‡†å¤‡ç”Ÿæˆé…ç½®
        generation_config = {
            "bos_token_id": paddleocr_vl_model.tokenizer.bos_token_id,
            "eos_token_id": paddleocr_vl_model.tokenizer.eos_token_id,
            "pad_token_id": paddleocr_vl_model.tokenizer.pad_token_id,
            "max_new_tokens": max_new_tokens,
            "do_sample": False,
        }
        
        # æ‰§è¡ŒOCRè¯†åˆ«
        start_time = time.perf_counter()
        response, history = paddleocr_vl_model.chat(
            input_ids=text_inputs["input_ids"],
            attention_mask=text_inputs["attention_mask"],
            pixel_values=images_info["pixel_values"],
            image_grid_thw=images_info["image_grid_thw"],
            generation_config=generation_config
        )
        elapsed_time = time.perf_counter() - start_time
        
        # æ ¼å¼åŒ–ç»“æœï¼ˆå¤„ç†ç‰¹æ®Šæ ‡è®°ï¼‰
        formatted_response = format_ocr_result(response)
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯è¡¨æ ¼æ ¼å¼ï¼ˆåŒ…å«Markdownè¡¨æ ¼ï¼‰
        is_table = formatted_response.strip().startswith('|') and '---' in formatted_response
        
 # æ ¼å¼åŒ–ç»“æœæ–‡æœ¬
        result_text = f"""ğŸ“„ OCRè¯†åˆ«ç»“æœ:
{formatted_response}

â±ï¸ æ‰§è¡Œæ—¶é—´: {elapsed_time:.3f} ç§’ ({elapsed_time*1000:.2f} æ¯«ç§’)
"""
        
        # å‡†å¤‡Markdownå¯è§†åŒ–å†…å®¹
        if is_table:
            # åªæœ‰è¡¨æ ¼æ‰è½¬æ¢ä¸ºMarkdownå¹¶å¯è§†åŒ–
            markdown_content = f"""## ğŸ“Š è¡¨æ ¼å¯è§†åŒ–

{formatted_response}

---
*æ‰§è¡Œæ—¶é—´: {elapsed_time:.3f} ç§’*
"""
        else:
            # éè¡¨æ ¼æƒ…å†µï¼Œç›´æ¥æ˜¾ç¤ºåŸå§‹æ–‡æœ¬ï¼ˆä¸è¿›è¡ŒMarkdownæ ¼å¼åŒ–ï¼‰
            markdown_content = f"""## ğŸ“„ è¯†åˆ«ç»“æœ

{response}

---
*æ‰§è¡Œæ—¶é—´: {elapsed_time:.3f} ç§’*
"""
        
        # è¿”å›ï¼šæ ¼å¼åŒ–æ–‡æœ¬ã€åŸå§‹ç»“æœã€Markdownå¯è§†åŒ–
        return result_text, response, markdown_content
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        return f"âŒ è¯†åˆ«å¤±è´¥: {str(e)}\n\nè¯¦ç»†ä¿¡æ¯:\n{error_detail}", None, None

# åˆ›å»ºGradioç•Œé¢
# æ·»åŠ å¼‚å¸¸å¤„ç†é…ç½®ï¼Œé¿å…å“åº”å†…å®¹é•¿åº¦é”™è¯¯
with gr.Blocks(
    title="PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ v2", 
    theme=gr.themes.Soft(),
    # æ·»åŠ è¿™äº›é…ç½®æ¥é¿å…å“åº”é—®é¢˜
    analytics_enabled=False,
) as demo:
    gr.Markdown(
        """
        # ğŸš€ PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ v2
        
        åŸºäºOpenVINOçš„PaddleOCR-VLæ¨¡å‹OCRè¯†åˆ«ç•Œé¢ï¼ˆä½¿ç”¨render_jinja_templateï¼‰
        
        ## ä½¿ç”¨è¯´æ˜
        1. é¦–å…ˆåœ¨"æ¨¡å‹è®¾ç½®"ä¸­åˆå§‹åŒ–æ¨¡å‹
        2. ä¸Šä¼ è¦è¯†åˆ«çš„å›¾ç‰‡
        3. é€‰æ‹©ä»»åŠ¡ç±»å‹æˆ–è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯
        4. ç‚¹å‡»"å¼€å§‹è¯†åˆ«"æŒ‰é’®
        """
    )
    
    with gr.Tab("æ¨¡å‹è®¾ç½®"):
        with gr.Row():
            with gr.Column():
                ov_model_path_input = gr.Textbox(
                    label="OpenVINOæ¨¡å‹è·¯å¾„",
                    value="./ov_paddleocr_vl_model",
                    placeholder="è¾“å…¥OpenVINOæ¨¡å‹è·¯å¾„"
                )
                device_type = gr.Dropdown(
                    label="è®¾å¤‡ç±»å‹",
                    choices=["CPU", "GPU"],
                    value="GPU"
                )
                template_path_input = gr.Textbox(
                    label="Chatæ¨¡æ¿æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                    value="",
                    placeholder="ç•™ç©ºä½¿ç”¨é»˜è®¤æ¨¡æ¿ï¼Œæˆ–è¾“å…¥æ¨¡æ¿æ–‡ä»¶è·¯å¾„"
                )
                llm_int4 = gr.Checkbox(label="LLM INT4å‹ç¼©", value=False)
                vision_int8 = gr.Checkbox(label="Vision INT8é‡åŒ–", value=False)
                llm_int8 = gr.Checkbox(label="LLM INT8é‡åŒ–", value=False)
                init_btn = gr.Button("åˆå§‹åŒ–æ¨¡å‹", variant="primary")
            with gr.Column():
                init_status = gr.Textbox(
                    label="åˆå§‹åŒ–çŠ¶æ€",
                    value="ç­‰å¾…åˆå§‹åŒ–...",
                    interactive=False,
                    lines=5
                )
    
    with gr.Tab("OCRè¯†åˆ«"):
        with gr.Row():
            with gr.Column():
                image_input = gr.Image(
                    label="ä¸Šä¼ å›¾ç‰‡ï¼ˆæ–¹å¼1ï¼šç›´æ¥ä¸Šä¼ ï¼‰",
                    type="pil",
                    sources=["upload", "clipboard"],
                )
                image_url_or_path = gr.Textbox(
                    label="å›¾ç‰‡è·¯å¾„æˆ–URLï¼ˆæ–¹å¼2ï¼šè¾“å…¥æœ¬åœ°è·¯å¾„æˆ–ç½‘ç»œURLï¼‰",
                    placeholder="ä¾‹å¦‚: ./image.jpg æˆ– https://example.com/image.png",
                    value="",
                    lines=1
                )
                gr.Markdown("**æç¤º**: å¯ä»¥ä½¿ç”¨æ–¹å¼1ä¸Šä¼ å›¾ç‰‡ï¼Œæˆ–ä½¿ç”¨æ–¹å¼2è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„æˆ–ç½‘ç»œå›¾ç‰‡URL")
                gr.Markdown("**æ³¨æ„**: å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´ä¸º1200x800å°ºå¯¸")
                task_type = gr.Dropdown(
                    label="ä»»åŠ¡ç±»å‹",
                    choices=["ocr", "table", "formula", "chart"],
                    value="ocr"
                )
                custom_prompt = gr.Textbox(
                    label="è‡ªå®šä¹‰æç¤ºè¯ï¼ˆå¯é€‰ï¼‰",
                    placeholder="ç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤æç¤ºè¯ï¼Œä¾‹å¦‚: OCR: æˆ– Table Recognition:",
                    lines=2
                )
                max_tokens = gr.Slider(
                    label="æœ€å¤§ç”Ÿæˆtokenæ•°",
                    minimum=128,
                    maximum=2048,
                    value=1024,
                    step=128
                )
                recognize_btn = gr.Button("å¼€å§‹è¯†åˆ«", variant="primary", size="lg")
            
            with gr.Column():
                markdown_output = gr.Markdown(
                    label="Markdownå¯è§†åŒ–ï¼ˆè¡¨æ ¼æ¸²æŸ“ï¼‰",
                    value="ç­‰å¾…è¯†åˆ«ç»“æœ...",
                )
                result_output = gr.Textbox(
                    label="è¯†åˆ«ç»“æœï¼ˆæ ¼å¼åŒ–åæ–‡æœ¬ï¼‰",
                    lines=15,
                    interactive=False
                )
                raw_result = gr.Textbox(
                    label="åŸå§‹ç»“æœï¼ˆæœªæ ¼å¼åŒ–ï¼‰",
                    lines=8,
                    interactive=True
                )
                gr.Markdown("**æç¤º**: æ ¼å¼åŒ–ç»“æœä¼šè‡ªåŠ¨å°†è¡¨æ ¼æ ‡è®°è½¬æ¢ä¸ºMarkdownè¡¨æ ¼æ ¼å¼ï¼Œå¹¶åœ¨ä¸Šæ–¹å¯è§†åŒ–æ˜¾ç¤º")
    
    with gr.Tab("ä½¿ç”¨è¯´æ˜"):
        gr.Markdown(
            """
            ## ğŸ“– ä½¿ç”¨è¯´æ˜
            
            ### 1. æ¨¡å‹åˆå§‹åŒ–
            - **OpenVINOæ¨¡å‹è·¯å¾„**: è½¬æ¢åçš„OpenVINOæ¨¡å‹è·¯å¾„
            - **è®¾å¤‡ç±»å‹**: é€‰æ‹©CPUæˆ–GPUï¼ˆæ¨èGPUï¼‰
            - **Chatæ¨¡æ¿æ–‡ä»¶**: å¯é€‰ï¼Œç•™ç©ºä½¿ç”¨é»˜è®¤æ¨¡æ¿
            - **é‡åŒ–é€‰é¡¹**: æ ¹æ®éœ€è¦é€‰æ‹©æ˜¯å¦å¯ç”¨é‡åŒ–ä»¥æå‡æ€§èƒ½
            
            ### 2. OCRè¯†åˆ«
            - **ä¸Šä¼ å›¾ç‰‡ï¼ˆæ–¹å¼1ï¼‰**: æ”¯æŒä¸Šä¼ æˆ–ç²˜è´´å›¾ç‰‡
            - **å›¾ç‰‡è·¯å¾„æˆ–URLï¼ˆæ–¹å¼2ï¼‰**: 
              - è¾“å…¥æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚: `./image.jpg` æˆ– `C:/images/test.png`
              - è¾“å…¥ç½‘ç»œå›¾ç‰‡URLï¼Œä¾‹å¦‚: `https://example.com/image.png`
              - æ³¨æ„ï¼šå¦‚æœä½¿ç”¨æ–¹å¼1ä¸Šä¼ äº†å›¾ç‰‡ï¼Œæ–¹å¼2ä¼šè¢«å¿½ç•¥
            - **å›¾ç‰‡å°ºå¯¸**: å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´ä¸º1200x800å°ºå¯¸
            - **ä»»åŠ¡ç±»å‹**: 
              - `ocr`: æ™®é€šæ–‡å­—è¯†åˆ«
              - `table`: è¡¨æ ¼è¯†åˆ«
              - `formula`: å…¬å¼è¯†åˆ«
              - `chart`: å›¾è¡¨è¯†åˆ«
            - **è‡ªå®šä¹‰æç¤ºè¯**: å¯ä»¥è¾“å…¥è‡ªå®šä¹‰çš„æç¤ºè¯
            - **æœ€å¤§tokenæ•°**: æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§é•¿åº¦
            
            ### 3. ç»“æœæŸ¥çœ‹
            - **è¯†åˆ«ç»“æœ**: æ˜¾ç¤ºå®Œæ•´çš„è¯†åˆ«ç»“æœå’Œæ‰§è¡Œæ—¶é—´
            - **åŸå§‹ç»“æœ**: ä»…æ˜¾ç¤ºè¯†åˆ«å‡ºçš„æ–‡æœ¬å†…å®¹ï¼Œå¯ä»¥å¤åˆ¶
            
            ## âš ï¸ æ³¨æ„äº‹é¡¹
            - é¦–æ¬¡ä½¿ç”¨éœ€è¦å…ˆåˆå§‹åŒ–æ¨¡å‹
            - æ¨¡å‹åˆå§‹åŒ–å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
            - è¯†åˆ«æ—¶é—´å–å†³äºå›¾ç‰‡å¤§å°å’Œæ¨¡å‹é…ç½®
            - æœ¬ç‰ˆæœ¬ä½¿ç”¨render_jinja_templateå’ŒPaddleOCRVLImageProcessor
            """
        )
    
    # ç»‘å®šäº‹ä»¶
    init_btn.click(
        fn=initialize_model,
        inputs=[ov_model_path_input, device_type, llm_int4, vision_int8, llm_int8, template_path_input],
        outputs=init_status
    )
    
    recognize_btn.click(
        fn=process_ocr,
        inputs=[image_input, image_url_or_path, task_type, max_tokens, custom_prompt],
        outputs=[result_output, raw_result, markdown_output]
    )

if __name__ == "__main__":
    import os
    import socket
    
    # å½»åº•ç¦ç”¨Gradioçš„ç½‘ç»œæ£€æŸ¥ï¼Œé¿å…è¿æ¥è¶…æ—¶å’Œ403é”™è¯¯
    os.environ["GRADIO_SERVER_NAME"] = "127.0.0.1"
    os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"
    os.environ["GRADIO_SERVER_PROXY"] = ""
    os.environ["NO_PROXY"] = "127.0.0.1,localhost"
    os.environ["no_proxy"] = "127.0.0.1,localhost"
    # ç¦ç”¨å¯åŠ¨äº‹ä»¶æ£€æŸ¥
    os.environ["GRADIO_SKIP_STARTUP_EVENTS"] = "1"
    
    def find_free_port(start_port=7860, max_attempts=10):
        """æŸ¥æ‰¾å¯ç”¨ç«¯å£"""
        for i in range(max_attempts):
            port = start_port + i
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('127.0.0.1', port))
                    return port
            except OSError:
                continue
        return None
    
    try:
        print("=" * 60)
        print("æ­£åœ¨å¯åŠ¨PaddleOCR-VL OCRè¯†åˆ«ç³»ç»Ÿ v2...")
        print("=" * 60)
        
        # æŸ¥æ‰¾å¯ç”¨ç«¯å£
        port = find_free_port(7860)
        if port is None:
            print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šç«¯å£")
            port = 7860
        
        print(f"è®¿é—®åœ°å€: http://127.0.0.1:{port}")
        print("=" * 60)
        
        # å°è¯•å¯åŠ¨ï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•å…¶ä»–ç«¯å£
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                demo.launch(
                    server_name="127.0.0.1",  # åªç›‘å¬æœ¬åœ°
                    server_port=port,          # ç«¯å£å·
                    share=False,               # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
                    inbrowser=False,           # ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨ï¼ˆé¿å…å¯åŠ¨äº‹ä»¶é—®é¢˜ï¼‰
                    show_error=True,           # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    quiet=False,               # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
                    favicon_path=None,         # ä¸ä½¿ç”¨favicon
                    prevent_thread_lock=False,   # å…è®¸åœ¨åå°è¿è¡Œ
                    # æ·»åŠ è¿™äº›å‚æ•°æ¥é¿å…å¯åŠ¨äº‹ä»¶æ£€æŸ¥å’Œå“åº”é—®é¢˜
                    max_threads=1,             # é™åˆ¶çº¿ç¨‹æ•°
                    # ä¿®å¤å“åº”å†…å®¹é•¿åº¦é—®é¢˜
                    max_file_size=None,        # ä¸é™åˆ¶æ–‡ä»¶å¤§å°ï¼ˆæˆ–è®¾ç½®ä¸€ä¸ªè¾ƒå¤§çš„å€¼ï¼‰
                    allowed_paths=None,        # å…è®¸æ‰€æœ‰è·¯å¾„
                )
                break  # æˆåŠŸå¯åŠ¨
            except Exception as e:
                if attempt < max_attempts - 1:
                    port = find_free_port(port + 1)
                    if port:
                        print(f"å°è¯•ç«¯å£ {port}...")
                        continue
                raise
        
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨:")
        print("   Windows: netstat -ano | findstr :7860")
        print("   Linux/Mac: lsof -i :7860")
        print("2. å°è¯•æ‰‹åŠ¨æŒ‡å®šç«¯å£:")
        print("   demo.launch(server_port=7861)")
        print("3. æ£€æŸ¥é˜²ç«å¢™/ä»£ç†è®¾ç½®:")
        print("   - ç¡®ä¿æ²¡æœ‰ä»£ç†é˜»æ­¢localhostè®¿é—®")
        print("   - ä¸´æ—¶å…³é—­é˜²ç«å¢™æµ‹è¯•")
        print("4. è®¾ç½®ç¯å¢ƒå˜é‡åé‡è¯•:")
        print("   set GRADIO_ANALYTICS_ENABLED=False")
        print("   set NO_PROXY=127.0.0.1,localhost")
        print("5. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•æ›´æ–°Gradio:")
        print("   pip install --upgrade gradio")
        raise

